{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PhonePe Pulse: unified loader + multi-select CLI (single cell) ===\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Iterable\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "DATA_ROOT = Path(\"data\")\n",
    "IGNORE_META = {\"success\", \"code\", \"responseTimestamp\", \"from\", \"to\"}\n",
    "SECTION_CHOICES = [\"aggregated\", \"map\", \"top\"]\n",
    "TYPE_CHOICES = [\"transaction\", \"user\", \"insurance\"]\n",
    "\n",
    "# ---------- IO & PATH HELPERS ----------\n",
    "def _read_json(p: Path) -> Optional[dict]:\n",
    "    try:\n",
    "        with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _to_float(x):\n",
    "    if isinstance(x, (int, float)): return float(x)\n",
    "    if isinstance(x, str):\n",
    "        try: return float(x.replace(\",\", \"\"))\n",
    "        except: return None\n",
    "    return None\n",
    "\n",
    "def _quarter_from_name(p: Path) -> Optional[int]:\n",
    "    try:\n",
    "        q = int(p.stem)\n",
    "        return q if q in (1,2,3,4) else None\n",
    "    except: return None\n",
    "\n",
    "def _year_from_parent(p: Path) -> Optional[int]:\n",
    "    try: return int(p.parent.name)\n",
    "    except: return None\n",
    "\n",
    "def _path_meta(p: Path) -> Dict[str, Optional[str]]:\n",
    "    \"\"\"\n",
    "    Examples:\n",
    "      data/aggregated/transaction/country/india/2019/1.json\n",
    "      data/aggregated/transaction/state/karnataka/2021/4.json\n",
    "      data/map/user/hover/country/india/2021/1.json\n",
    "      data/top/transaction/country/india/2021/4.json\n",
    "    \"\"\"\n",
    "    parts = p.parts\n",
    "    if \"data\" not in parts: return {}\n",
    "    i = parts.index(\"data\")\n",
    "    comps = parts[i:]\n",
    "    if len(comps) < 6: return {}\n",
    "\n",
    "    d = {\"section\": comps[1], \"dtype\": comps[2], \"map_kind\": None}\n",
    "    j = 3\n",
    "    if d[\"section\"] == \"map\" and comps[j] == \"hover\":\n",
    "        d[\"map_kind\"] = \"hover\"\n",
    "        j += 1\n",
    "    d[\"geo_level\"] = comps[j]; j += 1                # country | state\n",
    "    d[\"geo_name\"]  = comps[j]; j += 1                # india | state-name\n",
    "    try:\n",
    "        d[\"year\"] = int(comps[j]); d[\"quarter\"] = int(Path(comps[j+1]).stem)\n",
    "    except Exception:\n",
    "        d[\"year\"]    = _year_from_parent(p)\n",
    "        d[\"quarter\"] = _quarter_from_name(p)\n",
    "    return d\n",
    "\n",
    "# ---------- PARSERS (return list[dict]) ----------\n",
    "def _parse_agg_txn(payload: dict) -> List[dict]:\n",
    "    rows = []\n",
    "    for it in (payload.get(\"data\", {}).get(\"transactionData\") or []):\n",
    "        cat = it.get(\"name\")\n",
    "        for pi in (it.get(\"paymentInstruments\") or []):\n",
    "            if pi.get(\"type\") == \"TOTAL\":\n",
    "                rows.append({\"metric\":\"transactions\",\"category\":cat,\n",
    "                             \"count\":_to_float(pi.get(\"count\")),\n",
    "                             \"amount\":_to_float(pi.get(\"amount\"))})\n",
    "    return rows\n",
    "\n",
    "def _parse_agg_ins(payload: dict) -> List[dict]:\n",
    "    rows = []\n",
    "    for it in (payload.get(\"data\", {}).get(\"transactionData\") or []):\n",
    "        for pi in (it.get(\"paymentInstruments\") or []):\n",
    "            if pi.get(\"type\") == \"TOTAL\":\n",
    "                rows.append({\"metric\":\"insurance\",\"category\":it.get(\"name\",\"Insurance\"),\n",
    "                             \"count\":_to_float(pi.get(\"count\")),\n",
    "                             \"amount\":_to_float(pi.get(\"amount\"))})\n",
    "    return rows\n",
    "\n",
    "def _parse_agg_user(payload: dict) -> List[dict]:\n",
    "    rows = []\n",
    "    data = payload.get(\"data\", {})\n",
    "    agg  = data.get(\"aggregated\") or {}\n",
    "    if agg:\n",
    "        rows.append({\"metric\":\"users_summary\",\n",
    "                     \"registeredUsers\":_to_float(agg.get(\"registeredUsers\")),\n",
    "                     \"appOpens\":_to_float(agg.get(\"appOpens\")),\n",
    "                     \"brand\":None,\"brand_count\":None,\"brand_pct\":None})\n",
    "    for d in (data.get(\"usersByDevice\") or []):\n",
    "        rows.append({\"metric\":\"users_by_device\",\n",
    "                     \"registeredUsers\":None,\"appOpens\":None,\n",
    "                     \"brand\":d.get(\"brand\"),\n",
    "                     \"brand_count\":_to_float(d.get(\"count\")),\n",
    "                     \"brand_pct\":_to_float(d.get(\"percentage\"))})\n",
    "    return rows\n",
    "\n",
    "def _parse_map_txn_ins(payload: dict) -> List[dict]:\n",
    "    rows = []\n",
    "    for item in (payload.get(\"data\", {}).get(\"hoverDataList\") or []):\n",
    "        name = item.get(\"name\")\n",
    "        for m in (item.get(\"metric\") or []):\n",
    "            if m.get(\"type\") == \"TOTAL\":\n",
    "                rows.append({\"name\":name,\n",
    "                             \"count\":_to_float(m.get(\"count\")),\n",
    "                             \"amount\":_to_float(m.get(\"amount\"))})\n",
    "    return rows\n",
    "\n",
    "def _parse_map_user(payload: dict) -> List[dict]:\n",
    "    rows = []\n",
    "    for name, vals in (payload.get(\"data\", {}).get(\"hoverData\") or {}).items():\n",
    "        rows.append({\"name\":name,\n",
    "                     \"registeredUsers\":_to_float(vals.get(\"registeredUsers\")),\n",
    "                     \"appOpens\":_to_float(vals.get(\"appOpens\"))})\n",
    "    return rows\n",
    "\n",
    "def _parse_top_txn_ins(payload: dict) -> List[dict]:\n",
    "    rows = []\n",
    "    data = payload.get(\"data\", {}) or {}\n",
    "    for level in (\"states\",\"districts\",\"pincodes\"):\n",
    "        for item in (data.get(level) or []):\n",
    "            m = item.get(\"metric\") or {}\n",
    "            if m.get(\"type\") == \"TOTAL\":\n",
    "                rows.append({\"level\":level[:-1],\n",
    "                             \"name\":item.get(\"entityName\"),\n",
    "                             \"count\":_to_float(m.get(\"count\")),\n",
    "                             \"amount\":_to_float(m.get(\"amount\"))})\n",
    "    return rows\n",
    "\n",
    "def _parse_top_user(payload: dict) -> List[dict]:\n",
    "    rows = []\n",
    "    data = payload.get(\"data\", {}) or {}\n",
    "    def add(level):\n",
    "        for it in (data.get(level) or []):\n",
    "            rows.append({\"level\":level[:-1],\n",
    "                         \"name\":it.get(\"name\"),\n",
    "                         \"registeredUsers\":_to_float(it.get(\"registeredUsers\"))})\n",
    "    add(\"states\"); add(\"districts\"); add(\"pincodes\")\n",
    "    return rows\n",
    "\n",
    "# ---------- NORMALIZATION ----------\n",
    "def _normalize_file(p: Path) -> List[dict]:\n",
    "    meta = _path_meta(p)\n",
    "    if not meta: return []\n",
    "    payload = _read_json(p)\n",
    "    if not isinstance(payload, dict): return []\n",
    "    for k in list(payload.keys()):\n",
    "        if k in IGNORE_META:\n",
    "            payload.pop(k, None)\n",
    "\n",
    "    section, dtype = meta[\"section\"], meta[\"dtype\"]\n",
    "    rows: List[dict] = []\n",
    "    try:\n",
    "        if section == \"aggregated\":\n",
    "            if dtype == \"transaction\": rows = _parse_agg_txn(payload)\n",
    "            elif dtype == \"insurance\": rows = _parse_agg_ins(payload)\n",
    "            elif dtype == \"user\":      rows = _parse_agg_user(payload)\n",
    "        elif section == \"map\":\n",
    "            if dtype in (\"transaction\",\"insurance\"): rows = _parse_map_txn_ins(payload)\n",
    "            elif dtype == \"user\":                    rows = _parse_map_user(payload)\n",
    "        elif section == \"top\":\n",
    "            if dtype in (\"transaction\",\"insurance\"): rows = _parse_top_txn_ins(payload)\n",
    "            elif dtype == \"user\":                    rows = _parse_top_user(payload)\n",
    "    except Exception:\n",
    "        rows = []\n",
    "\n",
    "    for r in rows:\n",
    "        r.update(meta)\n",
    "    return rows\n",
    "\n",
    "def load_all_rows() -> pd.DataFrame:\n",
    "    files = sorted(DATA_ROOT.rglob(\"*.json\"))\n",
    "    out: List[dict] = []\n",
    "    for p in files:\n",
    "        q = _quarter_from_name(p); y = _year_from_parent(p)\n",
    "        if q is None or y is None: continue\n",
    "        out.extend(_normalize_file(p))\n",
    "    df = pd.DataFrame(out)\n",
    "    if not df.empty:\n",
    "        df[\"period\"] = pd.PeriodIndex(\n",
    "            df[\"year\"].astype(\"Int64\").astype(str) + \"Q\" + df[\"quarter\"].astype(\"Int64\").astype(str),\n",
    "            freq=\"Q\")\n",
    "        df[\"geo\"] = df[\"geo_level\"].str.cat(df[\"geo_name\"], sep=\":\")\n",
    "        df[\"section_type\"] = df[\"section\"].str.cat(df[\"dtype\"], sep=\"/\")\n",
    "    return df\n",
    "\n",
    "# ---------- CLI UTILS ----------\n",
    "def _pick(prompt: str, options: List[str]) -> str:\n",
    "    print(f\"\\n{prompt}\")\n",
    "    for i,o in enumerate(options,1):\n",
    "        print(f\"{i}. {o}\")\n",
    "    while True:\n",
    "        s = input(\"Choose number: \").strip()\n",
    "        try:\n",
    "            k = int(s); \n",
    "            if 1 <= k <= len(options):\n",
    "                return options[k-1]\n",
    "        except: pass\n",
    "        print(\"Invalid. Try again.\")\n",
    "\n",
    "def _pick_multi(prompt: str, options: List[str], allow_all=True) -> List[str]:\n",
    "    print(f\"\\n{prompt} (comma-separated indexes{' or all' if allow_all else ''})\")\n",
    "    for i,o in enumerate(options,1):\n",
    "        print(f\"{i}. {o}\")\n",
    "    while True:\n",
    "        s = input(\"Choose: \").strip().lower()\n",
    "        if allow_all and s in (\"all\",\"*\"): return options\n",
    "        try:\n",
    "            idxs = [int(x) for x in s.replace(\" \",\"\").split(\",\") if x]\n",
    "            picked = [options[i-1] for i in idxs if 1 <= i <= len(options)]\n",
    "            if picked:\n",
    "                seen=set(); out=[]\n",
    "                for x in picked:\n",
    "                    if x not in seen: out.append(x); seen.add(x)\n",
    "                return out\n",
    "        except: pass\n",
    "        print(\"Invalid. Try again.\")\n",
    "\n",
    "def _parse_years(user_in: str, available: Iterable[int]) -> List[int]:\n",
    "    avail = sorted(set(int(x) for x in available))\n",
    "    t = user_in.strip().lower()\n",
    "    if t in (\"all\",\"*\"): return avail\n",
    "    years=set()\n",
    "    for part in t.replace(\" \",\"\").split(\",\"):\n",
    "        if \"-\" in part:\n",
    "            a,b = part.split(\"-\",1)\n",
    "            try:\n",
    "                a,b=int(a),int(b)\n",
    "                for y in avail:\n",
    "                    if a<=y<=b: years.add(y)\n",
    "            except: pass\n",
    "        else:\n",
    "            try:\n",
    "                y=int(part)\n",
    "                if y in avail: years.add(y)\n",
    "            except: pass\n",
    "    return sorted(years) or avail\n",
    "\n",
    "def _parse_quarters(user_in: str) -> List[int]:\n",
    "    t = user_in.strip().lower()\n",
    "    if t in (\"all\",\"*\"): return [1,2,3,4]\n",
    "    qs=set()\n",
    "    for part in t.replace(\" \",\"\").split(\",\"):\n",
    "        try:\n",
    "            q=int(part)\n",
    "            if q in (1,2,3,4): qs.add(q)\n",
    "        except: pass\n",
    "    return sorted(qs) or [1,2,3,4]\n",
    "\n",
    "# ---------- PROGRAMMATIC API ----------\n",
    "def query_data(\n",
    "    sections: List[str],\n",
    "    types: List[str],\n",
    "    geo_level: str,        # \"country\" or \"state\"\n",
    "    geos: List[str],       # [\"india\"] or list of state names\n",
    "    years: List[int],\n",
    "    quarters: List[int],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter the normalized dataset programmatically.\n",
    "    \"\"\"\n",
    "    df = load_all_rows()\n",
    "    if df.empty: return df\n",
    "\n",
    "    mask = (\n",
    "        df[\"section\"].isin(sections)\n",
    "        & df[\"dtype\"].isin(types)\n",
    "        & (df[\"geo_level\"] == geo_level)\n",
    "        & df[\"geo_name\"].isin(geos)\n",
    "        & df[\"year\"].isin(years)\n",
    "        & df[\"quarter\"].isin(quarters)\n",
    "    )\n",
    "    out = df[mask].copy()\n",
    "    sort_cols = [c for c in [\"section\",\"dtype\",\"geo_level\",\"geo_name\",\"year\",\"quarter\"] if c in out.columns]\n",
    "    if sort_cols:\n",
    "        out = out.sort_values(sort_cols, kind=\"mergesort\")\n",
    "    return out\n",
    "\n",
    "# ---------- INTERACTIVE CLI (multi-select) ----------\n",
    "def interactive_query_cli(save_csv: bool = False, csv_name: str = \"selection.csv\") -> pd.DataFrame:\n",
    "    df = load_all_rows()\n",
    "    if df.empty:\n",
    "        raise SystemExit(\"No JSON data found under ./data\")\n",
    "\n",
    "    sections = _pick_multi(\"Sections\", SECTION_CHOICES)           # multiple\n",
    "    types    = _pick_multi(\"Types\", TYPE_CHOICES)                  # multiple\n",
    "    geo_level = _pick(\"Geography level\", [\"country\",\"state\"])\n",
    "\n",
    "    if geo_level == \"state\":\n",
    "        avail_states = sorted(df[(df.section.isin(sections)) &\n",
    "                                 (df.dtype.isin(types)) &\n",
    "                                 (df.geo_level==\"state\")][\"geo_name\"].dropna().unique().tolist())\n",
    "        if not avail_states:\n",
    "            raise SystemExit(\"No states available for that combination.\")\n",
    "        states = _pick_multi(\"States\", avail_states)\n",
    "        geos = states\n",
    "    else:\n",
    "        geos = [\"india\"]\n",
    "\n",
    "    subset = df[(df.section.isin(sections)) &\n",
    "                (df.dtype.isin(types)) &\n",
    "                (df.geo_level==geo_level) &\n",
    "                (df.geo_name.isin(geos))].copy()\n",
    "\n",
    "    years_avail = sorted(subset[\"year\"].dropna().astype(int).unique().tolist())\n",
    "    print(f\"\\nAvailable years: {years_avail}\")\n",
    "    years = _parse_years(input(\"Pick years (e.g. 'all', '2020-2022', '2019,2021'): \"), years_avail)\n",
    "\n",
    "    quarters = _parse_quarters(input(\"Pick quarters (e.g. 'all' or '1,3,4'): \"))\n",
    "\n",
    "    out = subset[subset[\"year\"].isin(years) & subset[\"quarter\"].isin(quarters)].copy()\n",
    "    print(f\"\\nRows selected: {len(out):,}\")\n",
    "\n",
    "    if save_csv and not out.empty:\n",
    "        out.to_csv(csv_name, index=False)\n",
    "        print(f\"Saved -> {csv_name}\")\n",
    "    return out\n",
    "\n",
    "# (No auto-execution on import)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Section\n",
      "1. aggregated\n",
      "2. map\n",
      "3. top\n",
      "\n",
      "Type\n",
      "1. transaction\n",
      "2. user\n",
      "3. insurance\n"
     ]
    }
   ],
   "source": [
    "df_view = interactive_query()\n",
    "df_view.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_view.to_csv(\"selection.csv\", index=False)\n",
    "print(\"Saved selection.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
